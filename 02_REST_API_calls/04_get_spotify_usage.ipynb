{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Grab spotify usage data data from REST API\n",
    "\n",
    "- Purpose: \n",
    "    - query timestamp of latest data point from ETL table,\n",
    "    - obtain a service pricipal OAUTH token,\n",
    "    - For each day from last point until today: gather transactional JSON data (paginated),\n",
    "    - concat and process data,\n",
    "    - insert data to interface table,\n",
    "    - add loading success/failure and stats to etl table.\n",
    "- Author: vsm\n",
    "- Date: 2025-07-08\n",
    "- Team: GS - BI/ERP\n",
    "\n",
    "## Requirements\n",
    "\n",
    "1. Update package lists\n",
    "`sudo apt-get update`\n",
    "\n",
    "2. Install unixODBC and PostgreSQL ODBC driver\n",
    "`sudo apt-get install -y unixodbc unixodbc-dev odbc-postgresql`\n",
    "\n",
    "3. Optional: also install PostgreSQL client utilities\n",
    "`sudo apt-get install -y postgresql-client`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d238c87",
   "metadata": {},
   "source": [
    "### Load Parameters and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-08 22:05:59,426 Loading Modules\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import hashlib\n",
    "import pyodbc\n",
    "import base64\n",
    "import urllib.parse\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# remove orphaned logging handlers\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(asctime)s %(message)s\")\n",
    "\n",
    "env_dict = dotenv_values(\"./.env_spotify\")\n",
    "\n",
    "API_CREDS = {\n",
    "    \"CLIENT_ID\": env_dict['CLIENT_ID'],\n",
    "    \"CLIENT_SECRET\": env_dict['CLIENT_SECRET'],\n",
    "    \"SCOPE\": env_dict['SCOPE'],\n",
    "    \"REDIRECT_URI\": env_dict['REDIRECT_URI'],\n",
    "    \"OAUTH_URL\": env_dict['OAUTH_URL'],\n",
    "    \"REST_URL\": env_dict['REST_URL'],\n",
    "}\n",
    "\n",
    "BI_META = {\n",
    "    \"BI_SERVICE_NAME\": env_dict['BI_SERVICE_NAME'],\n",
    "    \"BI_STAGING_TABLE\": env_dict['BI_STAGING_TABLE'],\n",
    "    \"BI_LOG_TABLE\": env_dict['BI_LOG_TABLE'],\n",
    "    \"BI_INGEST_TS\": env_dict['BI_INGEST_TS'],\n",
    "}\n",
    "\n",
    "SQL_CREDS = {\n",
    "    \"PG_SERVER\": env_dict['PG_SERVER'],\n",
    "    \"PG_PORT\": env_dict['PG_PORT'],\n",
    "    \"PG_DB\": env_dict['PG_DB'],\n",
    "    \"PG_SCHEMA\": env_dict['PG_SCHEMA'],\n",
    "    \"PG_USER\": env_dict['PG_USER'],\n",
    "    \"PG_PWD\": env_dict['PG_PWD'],\n",
    "}\n",
    "\n",
    "logging.info(\"Loading Modules\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae42978",
   "metadata": {},
   "source": [
    "## Authorization Code Flow Overview\n",
    "\n",
    "1. Redirect user to Spotify login & consent screen.\n",
    "\n",
    "2. Spotify redirects back with code → exchange this for an access_token and refresh_token.\n",
    "\n",
    "3. Use the access_token to call APIs on behalf of the user.\n",
    "\n",
    "4. Use the refresh_token to get a new access token when expired.\n",
    "\n",
    "### 1. Generate Auth URL & Open It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"client_id\": API_CREDS['CLIENT_ID'],\n",
    "    \"response_type\": \"code\",\n",
    "    \"redirect_uri\": API_CREDS['REDIRECT_URI'],\n",
    "    \"scope\": API_CREDS['SCOPE'],\n",
    "}\n",
    "\n",
    "auth_url = \"https://accounts.spotify.com/authorize?\" + urllib.parse.urlencode(params)\n",
    "print(\"Go to the following URL and authorize the app:\")\n",
    "print(auth_url)\n",
    "\n",
    "# Optional: open it automatically\n",
    "#import webbrowser\n",
    "#webbrowser.open(auth_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06549cf7",
   "metadata": {},
   "source": [
    "### 2. Manually Paste the Redirect URL and get Code from callback URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "redirected_url = input(\"Paste the full redirect URL here: \")\n",
    "code = urllib.parse.parse_qs(urllib.parse.urlparse(redirected_url).query)['code'][0]\n",
    "print(\"Auth code:\", code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65778867",
   "metadata": {},
   "source": [
    "### 3. Exchange Code for Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac30381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def get_tokens(code):\n",
    "    token_url = \"https://accounts.spotify.com/api/token\"\n",
    "\n",
    "    auth_header = base64.b64encode(f\"{API_CREDS['CLIENT_ID']}:{API_CREDS['CLIENT_SECRET']}\".encode()).decode()\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Basic {auth_header}\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"grant_type\": \"authorization_code\",\n",
    "        \"code\": code,\n",
    "        \"redirect_uri\": API_CREDS['REDIRECT_URI'],\n",
    "    }\n",
    "\n",
    "    res = requests.post(token_url, headers=headers, data=data)\n",
    "    res.raise_for_status()\n",
    "    return res.json()\n",
    "\n",
    "tokens = get_tokens(code)\n",
    "access_token = tokens[\"access_token\"]\n",
    "refresh_token = tokens[\"refresh_token\"]\n",
    "\n",
    "print(\"Access token:\", access_token)\n",
    "print(\"Refresh token:\", refresh_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c6cf7",
   "metadata": {},
   "source": [
    "### 4. Refresh access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1eb781",
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_token=''\n",
    "def refresh_access_token(refresh_token):\n",
    "    token_url = \"https://accounts.spotify.com/api/token\"\n",
    "    auth_header = base64.b64encode(f\"{API_CREDS['CLIENT_ID']}:{API_CREDS['CLIENT_SECRET']}\".encode()).decode()\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Basic {auth_header}\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"grant_type\": \"refresh_token\",\n",
    "        \"refresh_token\": refresh_token\n",
    "    }\n",
    "\n",
    "    res = requests.post(token_url, headers=headers, data=data)\n",
    "    res.raise_for_status()\n",
    "    return res.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609705b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_access_token(refresh_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286159cf",
   "metadata": {},
   "source": [
    "### Make testing Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd7bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Rope Ends – Pain of Salvation\n",
      "2. Lake of Fire – Meat Puppets\n",
      "3. Song to the Siren – Tim Buckley\n",
      "4. Look At The Fool - Remastered – Tim Buckley\n",
      "5. Grace – Jeff Buckley\n"
     ]
    }
   ],
   "source": [
    "access_token = ''\n",
    "\n",
    "res = requests.get(\n",
    "    \"https://api.spotify.com/v1/me/player/recently-played?limit=5\",\n",
    "    headers={\"Authorization\": f\"Bearer {access_token}\"}\n",
    ")\n",
    "\n",
    "for i, item in enumerate(res.json().get(\"items\", [])):\n",
    "    track = item['track']\n",
    "    print(f\"{i+1}. {track['name']} – {track['artists'][0]['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e860bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime(2025, 6, 30)\n",
    "\n",
    "after = int(dt.timestamp() * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Postgres Connection ===\n",
    "def get_sql_conn():\n",
    "    logging.info(f\"Connecting to DB\")\n",
    "    return pyodbc.connect(\n",
    "        f\"DRIVER={{PostgreSQL}};\"\n",
    "        f\"SERVER={SQL_CREDS['PG_SERVER']},{SQL_CREDS['PG_PORT']};\"\n",
    "        f\"PORT={SQL_CREDS['PG_PORT']};\"        \n",
    "        f\"DATABASE={SQL_CREDS['PG_DB']};\"\n",
    "        f\"UID={SQL_CREDS['PG_USER']};\"\n",
    "        f\"PWD={SQL_CREDS['PG_PWD']}\"\n",
    "    )\n",
    "\n",
    "# === Get latest timestamp ===\n",
    "def get_latest_timestamp(conn):\n",
    "    logging.info(f\"Getting maximum event timestamp\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SELECT COALESCE(MAX(event_time), '2025-06-30') FROM {SQL_CREDS['PG_SCHEMA']}.{BI_META['BI_STAGING_TABLE']}\")\n",
    "    result = cursor.fetchone()\n",
    "    return result[0] if result else datetime(2025, 6, 30)\n",
    "\n",
    "# === Get Token via Client Credentials Flow ===\n",
    "# === Note: this will not suffice for personal data\n",
    "def get_access_token():\n",
    "    logging.info(\"Getting OAuth\")\n",
    "    \n",
    "    auth_str = f\"{API_CREDS['CLIENT_ID']}:{API_CREDS['CLIENT_SECRET']}\"\n",
    "    b64_auth_str = base64.b64encode(auth_str.encode()).decode()\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Basic {b64_auth_str}',\n",
    "        'Content-Type': 'application/x-www-form-urlencoded'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'grant_type': 'client_credentials'\n",
    "    }\n",
    "\n",
    "    url = API_CREDS['OAUTH_URL']\n",
    "\n",
    "    res = requests.post(url, headers=headers, data=data)\n",
    "    res.raise_for_status()\n",
    "    \n",
    "    return res.json()['access_token']\n",
    "\n",
    "# === Fetch paginated spotify usage data ===\n",
    "def fetch_usage_data(timestamp_ms, token):\n",
    "    logging.info(\"Getting REST Data\")\n",
    "    limit = 20\n",
    "    rows = []\n",
    "\n",
    "    base_url = f\"{API_CREDS['REST_URL']}/me/player/recently-played\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    params = {\"after\": timestamp_ms, \"limit\": limit}\n",
    "    url = base_url\n",
    "    counter = 1\n",
    "\n",
    "    while url:\n",
    "        logging.info(f\"Page_{counter:02d}\")\n",
    "        resp = requests.get(url, headers=headers, params=params if counter == 1 else None)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        rows.extend(data.get(\"items\", []))\n",
    "        url = data.get(\"next\")\n",
    "        params = None  # Only apply params on the first page\n",
    "        counter += 1\n",
    "\n",
    "    return rows\n",
    "\n",
    "# === Sanitize JSON row ===\n",
    "def remove_available_markets(rows):\n",
    "    for item in rows:\n",
    "        track = item.get(\"track\", {})\n",
    "        track.pop(\"available_markets\", None)\n",
    "\n",
    "        album = track.get(\"album\", {})\n",
    "        album.pop(\"available_markets\", None)\n",
    "\n",
    "# === Hash JSON row ===\n",
    "def hash_row(row):\n",
    "    return hashlib.sha256(json.dumps(row, sort_keys=True).encode()).hexdigest()\n",
    "\n",
    "# === Insert new data (with hashdiff) ===\n",
    "def insert_new_data(conn, rows):\n",
    "    logging.info(f\"Inserting relevant data to DB\")\n",
    "    inserted_count = 0\n",
    "    duplicate_count =0\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    max_tf_ts = datetime(1900, 1, 1)\n",
    "\n",
    "    for row in rows:\n",
    "        tf_ts_str = row.get(BI_META['BI_INGEST_TS'])\n",
    "        if not tf_ts_str:\n",
    "            logging.warning(f\"JSON payload does not contain {BI_META['BI_INGEST_TS']} key\")\n",
    "            continue  # skip if missing transaction timestamp\n",
    "\n",
    "        try:\n",
    "            tf_ts = datetime.fromisoformat(tf_ts_str)\n",
    "        except ValueError:\n",
    "            logging.warning(f\"Row:{inserted_count + 1}: Timestamp {BI_META['BI_INGEST_TS']} malformed\")\n",
    "            continue  # skip malformed timestamp\n",
    "\n",
    "        hash_val = hash_row(row)\n",
    "        data_str = json.dumps(row)\n",
    "\n",
    "        # Skip duplicates\n",
    "        cursor.execute(f\"SELECT 1 FROM {SQL_CREDS['PG_SCHEMA']}.{BI_META['BI_STAGING_TABLE']} WHERE hash = ?\", (hash_val,))\n",
    "        if cursor.fetchone():\n",
    "            duplicate_count += 1\n",
    "            continue\n",
    "\n",
    "        # Insert new record\n",
    "        cursor.execute(\n",
    "            f\"INSERT INTO {SQL_CREDS['PG_SCHEMA']}.{BI_META['BI_STAGING_TABLE']} (event_time, data_json, hash) VALUES (?, ?, ?)\",\n",
    "            (tf_ts, data_str, hash_val)\n",
    "        )\n",
    "        inserted_count += 1\n",
    "\n",
    "        # Update max TF_TIMESTAMP\n",
    "        if not max_tf_ts or tf_ts > max_tf_ts:\n",
    "            max_tf_ts = tf_ts\n",
    "\n",
    "    conn.commit()\n",
    "    logging.info(f\"{inserted_count} rows inserted to DB, {duplicate_count} duplicates skipped\")\n",
    "    return inserted_count, max_tf_ts\n",
    "\n",
    "# === Log ETL run result ===\n",
    "def log_etl_result(conn, success, inserted_rows, max_ts):\n",
    "    logging.info(f\"Logging ETL run to DB\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        f\"INSERT INTO {SQL_CREDS['PG_SCHEMA']}.{BI_META['BI_LOG_TABLE']} (run_time, service_name, success, inserted_rows, max_event_time) VALUES (?, ?, ?, ?, ?)\",\n",
    "        (datetime.now(timezone.utc), BI_META['BI_SERVICE_NAME'], success, inserted_rows, max_ts)\n",
    "    )\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16276cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-08 22:48:59,105 Getting REST Data\n",
      "2025-07-08 22:48:59,109 Page_01\n",
      "2025-07-08 22:48:59,541 Page_02\n",
      "2025-07-08 22:49:02,501 Page_03\n",
      "2025-07-08 22:49:02,819 Page_04\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "timestamp_ms = int(time.time() * 1000) - 600 * 60 * 60 * 1000  # 6 hours ago in ms\n",
    "\n",
    "rows = fetch_usage_data(timestamp_ms, access_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2313eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_available_markets(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a242fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1751790440647"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "164f5b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 2025-07-02T19:25:34.902Z: Movement – LCD Soundsystem\n",
      "2. 2025-07-02T19:21:51.542Z: Slice Paper Wrists – Poison The Well\n",
      "3. 2025-07-02T19:17:55.546Z: Dragula – Rob Zombie\n",
      "4. 2025-07-02T19:14:12.345Z: 5 Minutes Alone – Pantera\n",
      "5. 2025-07-02T19:08:25.391Z: L'enfant sauvage – Gojira\n",
      "6. 2025-07-02T19:03:35.297Z: Save Me – Damageplan\n",
      "7. 2025-07-02T19:00:00.793Z: Fixation on the Darkness – Killswitch Engage\n",
      "8. 2025-07-02T18:55:56.476Z: Surreal Atrocites – A Life Once Lost\n",
      "9. 2025-07-02T18:36:56.972Z: Frankenstein – Clutch\n",
      "10. 2025-07-02T18:31:16.197Z: Love? – Strapping Young Lad\n",
      "11. 2025-07-02T18:26:21.706Z: Sirens – Samavayo\n",
      "12. 2025-07-02T18:21:13.456Z: Diana – Chelsea Wolfe\n",
      "13. 2025-07-02T18:16:55.576Z: Cabin Fever – Slomosa\n",
      "14. 2025-07-02T18:11:04.980Z: Siberian Kiss - 2009 Remaster – Glassjaw\n",
      "15. 2025-07-02T18:07:15.155Z: Tip Your Bartender – Glassjaw\n",
      "16. 2025-07-02T18:02:56.035Z: Broken Man – St. Vincent\n",
      "17. 2025-07-02T17:59:32.474Z: Carbonara – Spliff\n",
      "18. 2025-07-02T17:54:43.074Z: Make Sense of Any Mess – Animaux Formidables\n",
      "19. 2025-07-02T17:52:10.674Z: Orere-Elejigbo – The Lijadu Sisters\n",
      "20. 2025-07-02T17:47:22.487Z: Kwi A – Erol Josué\n",
      "21. 2025-07-02T21:07:34Z: Eriatarka – The Mars Volta\n",
      "22. 2025-07-02T21:00:48.268Z: Silenced – Mudvayne\n",
      "23. 2025-07-02T20:57:48.567Z: Symphony No.9 In E Minor, Op.95 \"Aus der neuen Welt\": IV. Finale. Allegro con fuoco - Excerpt – Antonín Dvořák\n",
      "24. 2025-07-02T20:55:40.309Z: Gayaneh: Sabre Dance – Aram Khachaturian\n",
      "25. 2025-07-02T20:53:21.784Z: There is Nothing New Under the Sun – Slomosa\n",
      "26. 2025-07-02T20:49:25.186Z: Sinnerman – Nina Simone\n",
      "27. 2025-07-02T20:39:02.444Z: Gloomy Sunday – Artie Shaw Orchestra\n",
      "28. 2025-07-02T20:35:13.421Z: Boom Boom Boom - Remastered – Nachtmahr\n",
      "29. 2025-07-02T20:31:34.160Z: Reden Und Atmen – Shnarph\n",
      "30. 2025-07-02T20:26:31.520Z: The Tallest Man, the Broadest Shoulders Part I: The Great Frontier Part II: Come to Me Only With Playthings Now – Sufjan Stevens\n",
      "31. 2025-07-02T20:18:13.876Z: Misprints – The Matthew Herbert Big Band\n",
      "32. 2025-07-02T20:11:58.815Z: The Tourist – Radiohead\n",
      "33. 2025-07-02T20:06:32.874Z: High Speed – Coldplay\n",
      "34. 2025-07-02T20:02:27.580Z: Chrome – Recoil\n",
      "35. 2025-07-02T19:55:05.324Z: Pink Maggit – Deftones\n",
      "36. 2025-07-02T19:47:38.248Z: A Call For Blood – Hatebreed\n",
      "37. 2025-07-02T19:43:33.992Z: Terrible Lie – Nine Inch Nails\n",
      "38. 2025-07-02T19:38:44.712Z: A Certain Shade of Green – Incubus\n",
      "39. 2025-07-02T19:35:01.614Z: 11 am – Incubus\n",
      "40. 2025-07-02T19:30:48.664Z: The Least Self-Destructive Self-Destructive Thing You Could Do – Respira\n",
      "41. 2025-07-07T18:37:40.224Z: Rope Ends – Pain of Salvation\n",
      "42. 2025-07-02T21:59:40.559Z: Lake of Fire – Meat Puppets\n",
      "43. 2025-07-02T21:57:42.661Z: Song to the Siren – Tim Buckley\n",
      "44. 2025-07-02T21:53:01.937Z: Look At The Fool - Remastered – Tim Buckley\n",
      "45. 2025-07-02T21:47:49.102Z: Grace – Jeff Buckley\n",
      "46. 2025-07-02T21:42:26.229Z: Sea of Love – Cat Power\n",
      "47. 2025-07-02T21:40:08.038Z: Señor Mouse – Chick Corea\n",
      "48. 2025-07-02T21:34:42.258Z: Mozart Piano Concerto No. 24 in C Minor, K.491: I. Allegro - Live – Wolfgang Amadeus Mozart\n",
      "49. 2025-07-02T21:14:50.971Z: Heartbeats – The Knife\n",
      "50. 2025-07-02T21:10:59.149Z: Evil – Interpol\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(rows):\n",
    "    track = row['track']\n",
    "    print(f\"{i+1}. {row.get('played_at')}: {track['name']} – {track['artists'][0]['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21be695a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Main ETL logic ===\n",
    "def run_etl():\n",
    "    conn = get_sql_conn()\n",
    "\n",
    "    # read maximum timestamp in staging_table\n",
    "    latest_ts = get_latest_timestamp(conn)\n",
    "    today = datetime.now(timezone.utc).date()\n",
    "    hour_str = '00'\n",
    "    logging.info(f\"Latest timestamp is: {latest_ts}\")\n",
    "    \n",
    "    inserted_total = 0\n",
    "    max_data_ts = latest_ts\n",
    "\n",
    "    try:\n",
    "        token = get_access_token()\n",
    "\n",
    "        for day in range(0, (today - latest_ts.date()).days + 1):\n",
    "            \n",
    "            if day == 0:\n",
    "                hour_str = f\"{latest_ts.hour:02d}\"\n",
    "\n",
    "            date_str = (latest_ts.date() + timedelta(days=day)).isoformat()\n",
    "\n",
    "            logging.info(f\"Daily extract for: {date_str}, with offset {hour_str} hours.\")\n",
    "            #daily_rows = []\n",
    "            daily_rows = fetch_usage_data(date_str, hour_str, token)\n",
    "\n",
    "            if daily_rows:\n",
    "                inserted, max_tf_ts = insert_new_data(conn, daily_rows)\n",
    "                inserted_total += inserted\n",
    "                if max_tf_ts and max_tf_ts > max_data_ts:\n",
    "                    max_data_ts = max_tf_ts\n",
    "\n",
    "        \n",
    "        log_etl_result(conn, True, inserted_total, max_data_ts)\n",
    "        logging.info(f\"✅ Success: Inserted {inserted_total} records.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        log_etl_result(conn, False, inserted_total, max_data_ts)\n",
    "        logging.info(f\"❌ Failure: {e}\")\n",
    "\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_etl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
